name: Daily Paper Digest

permissions:
  contents: write

on:
  # Run daily at 03:00 UTC (11:00 China time)
  schedule:
    - cron: '0 3 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      days_back:
        description: 'Days to look back for papers'
        required: false
        default: '1'
      dry_run:
        description: 'Dry run (no email)'
        required: false
        default: 'false'
        type: boolean

jobs:
  run-digest:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run paper digest
        env:
          # LLM 配置 (主模型 - 用于生成报告)
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_BASE_URL: ${{ secrets.LLM_BASE_URL }}
          LLM_MODEL: ${{ secrets.LLM_MODEL }}
          # LLM Filter 配置 (筛选模型 - 可以用更便宜的)
          LLM_FILTER_API_KEY: ${{ secrets.LLM_FILTER_API_KEY }}
          LLM_FILTER_BASE_URL: ${{ secrets.LLM_FILTER_BASE_URL }}
          LLM_FILTER_MODEL: ${{ secrets.LLM_FILTER_MODEL }}
          # Research enrichment
          TAVILY_API_KEY: ${{ secrets.TAVILY_API_KEY }}
          # 兼容旧配置
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          # Semantic Scholar memory (optional overrides)
          SEMANTIC_MEMORY_ENABLED: ${{ vars.SEMANTIC_MEMORY_ENABLED }}
          SEMANTIC_SEEN_TTL_DAYS: ${{ vars.SEMANTIC_SEEN_TTL_DAYS }}
          SEMANTIC_MEMORY_MAX_IDS: ${{ vars.SEMANTIC_MEMORY_MAX_IDS }}
          # Email
          RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
          # Optional: Cloudflare D1
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          D1_DATABASE_ID: ${{ secrets.D1_DATABASE_ID }}
        run: |
          DAYS="${{ github.event.inputs.days_back || '1' }}"
          DRY_RUN="${{ github.event.inputs.dry_run || 'false' }}"
          
          if [ "$DRY_RUN" = "true" ]; then
            python main.py --days $DAYS --dry-run
          else
            python main.py --days $DAYS
          fi

      - name: Persist semantic memory state
        run: |
          if [ ! -f semantic_scholar_memory.json ]; then
            echo "No semantic memory file found, skipping."
            exit 0
          fi

          if git diff --quiet -- semantic_scholar_memory.json; then
            echo "No semantic memory changes to persist."
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add semantic_scholar_memory.json
          git commit -m "chore: update semantic scholar memory [skip ci]" || {
            echo "Commit failed or no changes. Continuing."
            exit 0
          }

          # Best-effort push; do not fail digest delivery if push cannot be completed.
          branch="${GITHUB_REF_NAME:-main}"
          git pull --rebase origin "$branch" || true
          git push origin "HEAD:$branch" || echo "Memory push failed; continuing without failing workflow."
      
      - name: Upload report artifact (on dry run)
        if: ${{ github.event.inputs.dry_run == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: paper-report
          path: report_preview.html
          retention-days: 7
